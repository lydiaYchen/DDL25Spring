{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, ensure you have cloned the [course repository](https://github.com/lydiaYchen/DDL25Spring).\n",
    "\n",
    "Then, open the [interactive notebook version](https://github.com/lydiaYchen/DDL25Spring/blob/main/lab/homework-1.ipynb) of this homework from your local copy.\n",
    "\n",
    "For part A, fill in the code and answers within the notebook and save your changes.\n",
    "\n",
    "For part B, create and archive the necessary Python/shell scripts together.\n",
    "\n",
    "Finally, upload the notebook and the archive to the assignment in ILIAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When not otherwise specified, use the following parameter values in experiment runs:\n",
    "- `nr_clients` (N): 100\n",
    "- `lr`: 0.01\n",
    "- `client_fraction` (C): 0.1\n",
    "- `nr_local_epochs` (E): 1\n",
    "- `batch_size` (B): 100\n",
    "- `nr_rounds`: 10\n",
    "- `iid`: True\n",
    "\n",
    "For all exercises, pass `seed = 10` to calls for splitting data, server initialization, or plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tutorial_1a.hfl_complete import *\n",
    "\n",
    "n = 100\n",
    "lr = 0.01\n",
    "c = 0.1\n",
    "e = 1\n",
    "b = 100\n",
    "nr_rounds = 10\n",
    "iid = True\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A1: FedSGD with weights (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Implement a version of FedSGD that uses weights in its updates, like FedAvg, instead of the gradients from the version of the tutorials. The two FedSGD versions should have the same test accuracy after each round (with a tolerance of up to around 0.1%). To show this, compare their output for the following two scenarios over *5 rounds*:\n",
    "- `lr = 0.01, client_subsets = split(100, True, ...), client_fraction = 0.5`\n",
    "- `lr = 0.1, client_subsets = split(50, False, ...), client_fraction = 0.2`\n",
    "\n",
    "*Tip:* You can use the existing FedAvg implementation to minimize the amount of code writing required.\n",
    "\n",
    "_(1 point)_ Explain in which cases (for the different decentralized data learning parameters) weight and gradient FedSGD are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A2: Client number & fraction (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Run the necessary experiments to fill in the following table showing the final message count and test accuracy of FedSGD and FedAvg for different total client numbers:\n",
    "\n",
    "| Algorithm | N   | C   | Message count | Test accuracy |\n",
    "| --------- | --- | --- | ------------- | ------------- |\n",
    "| FedSGD    | 10  | 0.1 |               |               |\n",
    "| FedAvg    | 10  | 0.1 |               |               |\n",
    "| FedSGD    | 50  | 0.1 |               |               |\n",
    "| FedAvg    | 50  | 0.1 |               |               |\n",
    "| FedSGD    | 100 | 0.1 |               |               |\n",
    "| FedAvg    | 100 | 0.1 |               |               |\n",
    "\n",
    "Is the relationship between the metrics/algorithms and client numbers monotonous? Briefly explain your reasoning.\n",
    "\n",
    "_(2 points)_ Run the experiments to fill in the table when varying the fraction of clients used in every round:\n",
    "\n",
    "| Algorithm | N   | C    | Message count | Test accuracy |\n",
    "| --------- | --- | ---- | ------------- | ------------- |\n",
    "| FedSGD    | 100 | 0.01 |               |               |\n",
    "| FedAvg    | 100 | 0.01 |               |               |\n",
    "| FedSGD    | 100 | 0.1  |               |               |\n",
    "| FedAvg    | 100 | 0.1  |               |               |\n",
    "| FedSGD    | 100 | 0.2  |               |               |\n",
    "| FedAvg    | 100 | 0.2  |               |               |\n",
    "\n",
    "How do the observed relationships compare to before? Again, succintly argue your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A3: Local epoch count & (non-)IID data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(1 point)_ Create a line plot of the accuracy after each round for the following algorithm variants:\n",
    "\n",
    "- FedSGD\n",
    "- FedAvg (E=1)\n",
    "- FedAvg (E=2)\n",
    "- FedAvg (E=4)\n",
    "\n",
    "How does FedAvg compare to FedSGD? What is the effect of increasing the work clients perform locally for each update in FedAvg?\n",
    "\n",
    "_(2 points)_ Make one line plot of FedSGD and FedAvg under an IID and non-IID split for 15 rounds (leaving all other parameter values as they previously mentioned default). How does the non-IID setting affect the accuracy achieved by the two algorithms? What is the difference in terms of the smoothness of learning?\n",
    "\n",
    "_(2 points)_ Make another plot for only non-IID splits, including the FedSGD and FedAvg configs from the point above, and add a version for each with a learning rate of 0.001 and client fraction of 0.5. How does the stability of the new variants compare to the ones from before? Why do the changes in parameters have the observed effect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B1: Microbatch Pipeline Model Parallelism (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement pipeline parallelism with microbatches, as discussed during the lab.\n",
    "\n",
    "As with the other data/model parallelism examples, you will need a Python script for the nodes and a shell script to orchestrate execution.\n",
    "\n",
    "Be aware of the possibility of deadlocks: due to how `gloo` operates, it is possible to deadlock by having device 1 send $B_2$ to device 2 in the forward pass, and simultaneously, device 2 send $B_1$ in the backward pass.\n",
    "Since both sends will await corresponding receives, the training will stop indefinitely.\n",
    "\n",
    "Use `isend` & `irecv`, the asynchronous (non-blocking) versions of `send` & `recv` in `torch.distributed`.\n",
    "Each call of the two function returns a `Work` object, on which calling `wait()` blocks, if needed, until the message exchange finishes.\n",
    "Add comments or text explaining how you expect your implementation to work and test that it runs for the same number of steps and model architecture as in class.\n",
    "\n",
    "Note that `torch.distributed`'s implementation of `gloo` does not currently support properly asynchronous communication even when using the corresponding primitives.\n",
    "Thus, you will not see the same improvements in speed as with a backend like `nccl`.\n",
    "\n",
    "You may also use the fact that `torch` gradients naturally accumulate if not zeroed out.\n",
    "Also, scaling the loss by a constant is equivalent to scaling the resulting gradients by the same constant.\n",
    "\n",
    "You can rely on receiving messages in the same order they get sent between any device pair.\n",
    "The `(i)send/recv` functions all support a `tag` attribute to match messages explicitly.\n",
    "Although using it is good practice, it is not required.\n",
    "\n",
    "You can refer to the [documentation](https://pytorch.org/docs/stable/distributed.html) and, if helpful, a related [tutorial](https://brsoff.github.io/tutorials/intermediate/dist_tuto.html) on the PyTorch website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B2: Joint Data & Model Parallelism (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a training setup that uses data and model parallelism together.\n",
    "\n",
    "Create 2 pipelines of 3 stages running sequentially, where each stage works with 3 sequential micro-batches.\n",
    "\n",
    "Once again, add comments or text explaining your implementation and test it on the setting that mimics those from the class.\n",
    "\n",
    "You can use groups from `torch.distributed` to handle reduce operations between a subset of all workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
